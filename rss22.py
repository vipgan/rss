import asyncio
import aiohttp
import logging
import json
import os
import re
from datetime import datetime
from feedparser import parse
from telegram import Bot
from dotenv import load_dotenv
from aiohttp import ClientTimeout

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®RSSæº
RSS_FEEDS = [   
    'https://blog.090227.xyz/atom.xml',
    'https://www.freedidi.com/feed',
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCvijahEyGtvMpmMHBu4FS2w', # é›¶åº¦è§£è¯´
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC96OvMh0Mb_3NmuE8Dpu7Gg', # ææœºé›¶è·ç¦»
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCQoagx4VHBw3HkAyzvKEEBA', # ç§‘æŠ€å…±äº«
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCbCCUH8S3yhlm7__rhxR2QQ', # ä¸è‰¯æ—
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCMtXiCoKFrc2ovAGc1eywDg', # ä¸€ä¼‘
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCii04BCvYIdQvshrdNDAcww', # æ‚Ÿç©ºçš„æ—¥å¸¸
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCJMEiNh1HvpopPU3n9vJsMQ', # ç†ç§‘ç”·å£«
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCYjB6uufPeHSwuHs8wovLjg', # ä¸­æŒ‡é€š
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCSs4A6HYKmHA2MG_0z-F0xw', # ææ°¸ä¹è€å¸ˆ
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCZDgXi7VpKhBJxsPuZcBpgA', # å¯æ©KeEn
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCxukdnZiXnTFvjF5B5dvJ5w', # ç”¬å“¥ä¾ƒä¾ƒä¾ƒygkkk
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCUfT9BAofYBKUTiEVrgYGZw', # ç§‘æŠ€åˆ†äº«
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC51FT5EeNPiiQzatlA2RlRA', # ä¹Œå®¢wuke
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCDD8WJ7Il3zWBgEYBUtc9xQ', # jack stone
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCWurUlxgm7YJPPggDz9YJjw', # ä¸€ç“¶å¥¶æ²¹
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCvENMyIFurJi_SrnbnbyiZw', # é…·å‹ç¤¾
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCmhbF9emhHa-oZPiBfcLFaQ', # WenWeekly
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC3BNSKOaphlEoK4L7QTlpbA', # ä¸­å¤–è§‚å¯Ÿ
]

SECOND_RSS_FEEDS = [
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCUNciDq-y6I6lEQPeoP-R5A', # è‹æ’è§‚å¯Ÿ
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCXkOTZJ743JgVhJWmNV8F3Q', # å¯’åœ‹äºº
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC2r2LPbOUssIa02EbOIm7NA', # æ˜Ÿçƒç†±é»
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCF-Q1Zwyn9681F7du8DMAWg', # è¬å®—æ¡“-è€è¬ä¾†äº†
   # 'https://www.youtube.com/feeds/videos.xml?channel_id=UCOSmkVK2xsihzKXQgiXPS4w', # å†å²å“¥
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCSYBgX9pWGiUAcBxjnj6JCQ', # éƒ­æ­£äº®é »é“
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCNiJNzSkfumLB7bYtXcIEmg', # çœŸçš„å¾ˆåšé€š
 #   'https://www.youtube.com/feeds/videos.xml?channel_id=UCG_gH6S-2ZUOtEw27uIS_QA', # 7Carå°ä¸ƒè»Šè§€é»
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCJ5rBA0z4WFGtUTS83sAb_A', # POP Radioè¯æ’­ç¶²
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCQeRaTukNYft1_6AZPACnog', # Asmongold TV
    'https://rss.penggan.us.kg/rss/4734eed5ffb55689bfe8ebc4f55e63bd_chinese_simplified', # Asmongold TV
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCN0eCImZY6_OiJbo8cy5bLw', # å±ˆæ©ŸTV
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCb3TZ4SD_Ys3j4z0-8o6auA', # BBC News ä¸­æ–‡
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCiwt1aanVMoPYUt_CQYCPQg', # å…¨çƒå¤§è¦–é‡
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC000Jn3HGeQSwBuX_cLDK8Q', # æˆ‘æ˜¯æŸ³å‚‘å…‹
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCQFEBaHCJrHu2hzDA_69WQg', # å›½æ¼«è¯´
    'https://www.youtube.com/feeds/videos.xml?channel_id=UChJ8YKw6E1rjFHVS9vovrZw', # BNE TV - æ–°è¥¿å…°ä¸­æ–‡å›½é™…é¢‘é“
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCXk0rwHPG9eGV8SaF2p8KUQ', # çƒé´‰ç¬‘ç¬‘

# å½±è§†
    'https://www.youtube.com/feeds/videos.xml?channel_id=UC7Xeh7thVIgs_qfTlwC-dag', # Marc TV
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCqWNOHjgfL8ADEdXGznzwUw', # æ‚¦è€³éŸ³ä¹é…±
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCCD14H7fJQl3UZNWhYMG3Mg', # æ¸©åŸé²¤
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCQO2T82PiHCYbqmCQ6QO6lw', # æœˆäº®èªª
   # 'https://www.youtube.com/feeds/videos.xml?channel_id=UCKyDmY3R_xGKz8IjvbijiHA', # çŠçŠè¿½å‰§ç¤¾
    'https://www.youtube.com/feeds/videos.xml?channel_id=UClyVC2wh_2fQhU0hPdXA4rw', # çƒ­é—¨å¤é£
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UC1ISajIKfRN359MMmtckUTg', # Taiwanese Pop Mix
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCQFyMGc6h30NMCd6HCk0ZPA', # å“”å“©å“”å“©åŠ¨ç”»
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCQatgKoA7lylp_UzvsLCgcw', # è…¾è®¯è§†é¢‘
  #  'https://www.youtube.com/feeds/videos.xml?channel_id=UCUhpu5MJQ_bjPkXO00jyxsw', # çˆ±å¥‡è‰º
    'https://www.youtube.com/feeds/videos.xml?channel_id=UCHW6W9g2TJL2_Lf7GfoI5kg', # ç”µå½±æ”¾æ˜ å…
]

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•
script_dir = os.path.dirname(os.path.abspath(__file__))
# å®šä¹‰ rss2.json æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
RSS_STATUS_FILE = os.path.join(script_dir, 'rss2.json')
# é…ç½®æ—¥å¿—
log_path = os.path.join(script_dir, 'rss2.log')

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_path),  # ä½¿ç”¨ç»å¯¹è·¯å¾„
        logging.StreamHandler()
    ]
)

def load_rss_status():
    """åŠ è½½å¤„ç†çŠ¶æ€ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    try:
        with open(RSS_STATUS_FILE, 'r') as f:  # ä½¿ç”¨ç»å¯¹è·¯å¾„
            return json.loads(f.read())
    except FileNotFoundError:
        logging.info("çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
        return {}
    except json.JSONDecodeError:
        logging.warning("çŠ¶æ€æ–‡ä»¶æŸåï¼Œé‡ç½®ä¸ºé»˜è®¤çŠ¶æ€")
        return {}

def save_rss_status(status):
    """ä¿å­˜å¤„ç†çŠ¶æ€ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
    with open(RSS_STATUS_FILE, 'w') as f:  # ä½¿ç”¨ç»å¯¹è·¯å¾„
        json.dump(status, f, indent=2, ensure_ascii=False)

def clean_title(title):
    """æ¸…ç†æ ‡é¢˜ç‰¹æ®Šå­—ç¬¦"""
    return re.sub(r'[^\w\s\u4e00-\u9fa5.,!?;:"\'()\-]+', '', title).strip()

def parse_datetime(pub_date):
    """è§£æå‘å¸ƒæ—¶é—´"""
    try:
        return datetime(*pub_date[:6]) if pub_date else datetime.now()
    except TypeError:
        return datetime.now()

async def process_feed(session, feed_url, status, bot, chat_ids, max_retries=3):
    """å¤„ç†å•ä¸ªRSSæº, å¸¦æœ‰é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            # è·å–RSSå†…å®¹
            async with session.get(feed_url, timeout=30) as response:
                if response.status != 200:
                    logging.warning(f"è¯·æ±‚å¤±è´¥: {feed_url} çŠ¶æ€ç  {response.status}")
                    return

                feed = parse(await response.text())
                if not feed.entries:
                    logging.warning(f"æ— æ•ˆçš„RSSæº: {feed_url}")
                    return

                # è§£ææ¡ç›®
                feed_title = feed.feed.get('title', 'æœªçŸ¥æ¥æº').strip()
                entries = []
                for entry in feed.entries:
                    try:
                        pub_date = parse_datetime(entry.get('published_parsed'))
                        entries.append({
                            'guid': entry.get('id', entry.link),
                            'pubdate': pub_date,
                            'title': clean_title(entry.title),
                            'link': entry.link
                        })
                    except Exception as e:
                        logging.warning(f"æ¡ç›®è§£æå¤±è´¥: {e}")
                        continue

                # æ’åºå’Œç­›é€‰æ–°æ¡ç›®
                entries.sort(key=lambda x: x['pubdate'], reverse=True)
                last_status = status.get(feed_url, {})
                last_guid = last_status.get('guid')
                last_date = datetime.fromisoformat(last_status['pubdate']) if 'pubdate' in last_status else None

                new_entries = []
                for entry in entries:
                    if entry['guid'] == last_guid or (last_date and entry['pubdate'] <= last_date):
                        break
                    new_entries.append(entry)

                # å‘é€é€šçŸ¥
                if new_entries:
                    message = [f"ğŸ“¢ {feed_title}\n"]
                    for idx, entry in enumerate(reversed(new_entries), 1):
                        message.append(f"{idx}. {entry['title']}\nğŸ”— {entry['link']}\n")
                    message.append(f"âœ… æ–°å¢ {len(new_entries)} æ¡å†…å®¹")

                    for chat_id in chat_ids:
                        await bot.send_message(
                            chat_id=chat_id,
                            text="\n".join(message),
                            disable_web_page_preview=False
                        )
                        await asyncio.sleep(1)

                    # æ›´æ–°çŠ¶æ€
                    status[feed_url] = {
                        'guid': entries[0]['guid'],
                        'pubdate': entries[0]['pubdate'].isoformat()
                    }
                    save_rss_status(status)  # åŒæ­¥ä¿å­˜
                return  # æˆåŠŸå¤„ç†ï¼Œé€€å‡ºé‡è¯•å¾ªç¯

        except Exception as e:
            logging.error(f"å¤„ç†æºæ—¶å‘ç”Ÿé”™è¯¯ {feed_url} (å°è¯• {attempt+1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(5 * (attempt + 1))  # æŒ‡æ•°é€€é¿

    logging.error(f"å¤„ç†æº {feed_url} å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")


async def process_feed_with_semaphore(semaphore, session, feed_url, status, bot, chat_ids):
    async with semaphore:
        await process_feed(session, feed_url, status, bot, chat_ids)


async def main():
    """ä¸»å‡½æ•°"""
    # è¯»å–é…ç½®
    RSS_TOKEN = os.getenv("RSS_TOKEN")
    YOUTUBE_TOKEN = os.getenv("YOUTUBE_RSS")
    CHAT_IDS = os.getenv("TELEGRAM_CHAT_ID", "").split(",")

    if not RSS_TOKEN or not YOUTUBE_TOKEN:
        logging.error("ç¼ºå°‘æœºå™¨äººTokené…ç½®")
        return

    # åˆå§‹åŒ–æœºå™¨äºº
    main_bot = Bot(token=RSS_TOKEN)
    second_bot = Bot(token=YOUTUBE_TOKEN)
    status = load_rss_status()  # åŒæ­¥åŠ è½½

    # åˆ›å»ºä¿¡å·é‡
    semaphore = asyncio.Semaphore(5)  # é™åˆ¶å¹¶å‘æ•°ä¸º 5

    timeout = ClientTimeout(total=60) # è®¾ç½®æ€»è¶…æ—¶æ—¶é—´ä¸º60ç§’
    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit=100), timeout=timeout) as session: # å¢å¤§è¿æ¥æ± å¤§å°
        tasks = []
        for feed in RSS_FEEDS:
            tasks.append(process_feed_with_semaphore(semaphore, session, feed, status, main_bot, CHAT_IDS))
            await asyncio.sleep(0.5) #å»¶è¿Ÿ 0.5 ç§’

        for feed in SECOND_RSS_FEEDS:
            tasks.append(process_feed_with_semaphore(semaphore, session, feed, status, second_bot, CHAT_IDS))
            await asyncio.sleep(0.5)  # å»¶è¿Ÿ 0.5 ç§’

        await asyncio.gather(*tasks)

if __name__ == "__main__":
    asyncio.run(main())
